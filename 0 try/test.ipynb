{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2fe31457",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6053917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import (make_scorer, accuracy_score, precision_score, recall_score,\n",
    "                             f1_score, confusion_matrix, classification_report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9061ba28",
   "metadata": {},
   "source": [
    "Extract the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "20b98bd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1259, 27)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/raw/survey.csv\")\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "c51454d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = \"treatment\"  # <-- your binary target (Yes/No)\n",
    "gender_col = \"Gender\"     # <-- gender column name\n",
    "\n",
    "# Make target numeric\n",
    "df[target_col] = df[target_col].map({\"Yes\": 1, \"No\": 0}).astype(int)\n",
    "\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21bae5b",
   "metadata": {},
   "source": [
    "**Feature engineering**\n",
    "\n",
    "separate target and features + drop unused features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f0cebafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Timestamp','Country','state','comments','treatment'], axis=1)\n",
    "y = df['treatment']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f930d419",
   "metadata": {},
   "source": [
    "divide features into categorical and numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "4692ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_features = X.select_dtypes(include=[\"object\"])\n",
    "numeric_features = X.select_dtypes(include=[\"int64\", \"float64\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f986c38e",
   "metadata": {},
   "source": [
    "create a regex to clean the gender feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "109f5639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_simplify(gen):\n",
    "\n",
    "    s = str(gen).strip().lower()\n",
    "    s = re.sub(r\"[\\W_]+\", \" \", s).strip()\n",
    "\n",
    "    if s in {\"m\", \"male\", \"man\",\"make\", \"mal\",\"malr\",\"msle\",\"masc\",\"mail\", \"boy\"}:\n",
    "        return \"Male\"\n",
    "    if s in {\"f\", \"female\", \"woman\",\"femake\", \"femail\",\"femme\", \"girl\"}:\n",
    "        return \"Female\"\n",
    "    if s in {\"nb\", \"n\", \"nonbinary\", \"non binary\"}:\n",
    "        return \"Other\"\n",
    "\n",
    "    # Detect more complex patterns\n",
    "    if re.search(r\"\\b(female|woman|girl|femme)\\b\", s):\n",
    "        return \"Female\"\n",
    "    if re.search(r\"\\b(male|man|boy|masc)\\b\", s):\n",
    "        return \"Male\"\n",
    "\n",
    "    # Otherwise, everything else -> Other\n",
    "    return \"Other\"\n",
    "\n",
    "\n",
    "def simplify_gender_df(X):\n",
    "    # If it's already a DataFrame, take the FIRST (and only) column\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        col = X.columns[1]                # <-- was [1]; must be [0]\n",
    "        series = X[col]\n",
    "    else:\n",
    "        # Coerce to ndarray and normalize shapes\n",
    "        X = np.asarray(X, dtype=object)\n",
    "        if X.ndim == 1:\n",
    "            series = pd.Series(X)\n",
    "        elif X.ndim == 2 and X.shape[1] == 1:\n",
    "            series = pd.Series(X[:, 0])\n",
    "        else:\n",
    "            raise ValueError(f\"Expected a single column, got shape {X.shape}\")\n",
    "\n",
    "    # Apply your regex mapper and return a ONE-COLUMN DataFrame\n",
    "    out = series.apply(gender_simplify)\n",
    "    return out.to_frame(name=getattr(series, \"name\", \"gender\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc869b3",
   "metadata": {},
   "source": [
    "apply regex to gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b1753140",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = X.select_dtypes(include=[\"number\", \"bool\"]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=[\"object\", \"category\"]).columns.tolist()\n",
    "other_categoricals = [c for c in categorical_features if c != 'Gender']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e86048d",
   "metadata": {},
   "source": [
    "Define preprocessing pipelines and models to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1f79e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_pipeline = Pipeline([\n",
    "    (\"impute\",   SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"simplify\", FunctionTransformer(simplify_gender_df, feature_names_out=\"one-to-one\",validate=False)),\n",
    "    (\"ohe\",      OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "cat_pipeline = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"ohe\",    OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "])\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "    (\"impute\", SimpleImputer(strategy=\"median\")),\n",
    "])\n",
    "\n",
    "\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\",    num_pipeline, numeric_features),\n",
    "    (\"cat\",    cat_pipeline, other_categoricals),\n",
    "    (\"gender\", gender_pipeline, ['Gender']),\n",
    "])\n",
    "\n",
    "# ----------------------------\n",
    "# Models\n",
    "# ----------------------------\n",
    "log_reg = LogisticRegression(max_iter=2000)\n",
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "xgb_clf = XGBClassifier(\n",
    "    n_estimators=500,   \n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": log_reg,\n",
    "    \"Decision Tree\": tree_clf,\n",
    "    \"XGBoost\": xgb_clf\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f02a37a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\OneDrive\\Documentos\\MLOPS\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 89 iteration(s) (status=2):\n",
      "ABNORMAL: \n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\dell\\OneDrive\\Documentos\\MLOPS\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:473: ConvergenceWarning: lbfgs failed to converge after 21 iteration(s) (status=2):\n",
      "ABNORMAL: \n",
      "\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Logistic Regression (5-fold CV) ===\n",
      "Accuracy : 0.732 ± 0.047\n",
      "Precision: 0.753 ± 0.034\n",
      "Recall   : 0.697 ± 0.091\n",
      "F1       : 0.722 ± 0.064\n",
      "\n",
      "=== Decision Tree (5-fold CV) ===\n",
      "Accuracy : 0.658 ± 0.045\n",
      "Precision: 0.662 ± 0.041\n",
      "Recall   : 0.661 ± 0.059\n",
      "F1       : 0.661 ± 0.049\n",
      "\n",
      "=== XGBoost (5-fold CV) ===\n",
      "Accuracy : 0.728 ± 0.026\n",
      "Precision: 0.728 ± 0.025\n",
      "Recall   : 0.739 ± 0.037\n",
      "F1       : 0.733 ± 0.027\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scoring = {\n",
    "    \"accuracy\":  make_scorer(accuracy_score),\n",
    "    \"precision\": make_scorer(precision_score, zero_division=0),\n",
    "    \"recall\":    make_scorer(recall_score,    zero_division=0),\n",
    "    \"f1\":        make_scorer(f1_score,        zero_division=0)\n",
    "}\n",
    "\n",
    "for name, est in models.items():\n",
    "    pipe = Pipeline([(\"preprocess\", preprocess), (\"model\", est)])\n",
    "    res = cross_validate(pipe, X, y, cv=cv, scoring=scoring)\n",
    "    print(f\"\\n=== {name} (5-fold CV) ===\")\n",
    "    print(f\"Accuracy : {res['test_accuracy'].mean():.3f} ± {res['test_accuracy'].std():.3f}\")\n",
    "    print(f\"Precision: {res['test_precision'].mean():.3f} ± {res['test_precision'].std():.3f}\")\n",
    "    print(f\"Recall   : {res['test_recall'].mean():.3f} ± {res['test_recall'].std():.3f}\")\n",
    "    print(f\"F1       : {res['test_f1'].mean():.3f} ± {res['test_f1'].std():.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "138861e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Test Set Metrics (XGB) ===\n",
      "Accuracy : 0.6865079365079365\n",
      "Precision: 0.7168141592920354\n",
      "Recall   : 0.6328125\n",
      "F1       : 0.6721991701244814\n",
      "\n",
      "Confusion matrix:\n",
      " [[92 32]\n",
      " [47 81]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.74      0.70       124\n",
      "           1       0.72      0.63      0.67       128\n",
      "\n",
      "    accuracy                           0.69       252\n",
      "   macro avg       0.69      0.69      0.69       252\n",
      "weighted avg       0.69      0.69      0.69       252\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model = models[\"XGBoost\"]\n",
    "final_pipe  = Pipeline([(\"preprocess\", preprocess), (\"model\", final_model)])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "final_pipe.fit(X_train, y_train)\n",
    "y_pred = final_pipe.predict(X_test)\n",
    "\n",
    "print(\"\\n=== Test Set Metrics (XGB) ===\")\n",
    "print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred, zero_division=0))\n",
    "print(\"Recall   :\", recall_score(y_test, y_pred, zero_division=0))\n",
    "print(\"F1       :\", f1_score(y_test, y_pred, zero_division=0))\n",
    "\n",
    "# Confusion matrix + per-class report\n",
    "print(\"\\nConfusion matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
